{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK01trNRvmYK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier # Corrected typo here\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset using the Kaggle Hub API\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
        "\n",
        "# Load the dataset from the downloaded path\n",
        "file_path = f'{path}/heart_disease_uci.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Dataset downloaded and loaded successfully.\")\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OKeZIBvg4j-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial inspection\n",
        "print(\"Dataset Information:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "SdEBUBgG4mHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "kjy-6GVj4olk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='num', data=df, palette='viridis', hue='num', legend=False)\n",
        "plt.title('Distribution of Heart Disease (1 = Disease, 0 = No Disease)')\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uj2HOIaV4qhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize the relationship between key features and the target\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "fig.suptitle('Key Features vs. Heart Disease', fontsize=16)\n",
        "\n",
        "# Age vs. Target\n",
        "sns.histplot(ax=axes[0, 0], data=df, x='age', hue='num', multiple='stack', palette='plasma').set_title('Age Distribution by Target')\n",
        "\n",
        "# Max Heart Rate vs. Target\n",
        "sns.boxplot(ax=axes[0, 1], data=df, x='num', y='thalch', palette='magma', hue='num', legend=False).set_title('Max Heart Rate by Target')\n",
        "\n",
        "# Chest Pain Type vs. Target\n",
        "cp_plot = sns.countplot(ax=axes[1, 0], data=df, x='cp', hue='num', palette='cividis')\n",
        "cp_plot.set_title('Chest Pain Type by Target')\n",
        "cp_plot.set_xticks(range(len(df['cp'].unique())))\n",
        "cp_plot.set_xticklabels(['Typical Angina', 'Atypical Angina', 'Non-anginal Pain', 'Asymptomatic'])\n",
        "\n",
        "# Sex vs. Target\n",
        "sex_plot = sns.countplot(ax=axes[1, 1], data=df, x='sex', hue='num', palette='inferno')\n",
        "sex_plot.set_title('Sex by Target')\n",
        "sex_plot.set_xticks(range(len(df['sex'].unique())))\n",
        "sex_plot.set_xticklabels(['Female', 'Male'])\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CZYTTTO64suM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "# Select only numerical columns for correlation calculation\n",
        "numerical_df = df.select_dtypes(include=np.number)\n",
        "sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aCEhZyxT4vK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "s1tYOYr24xg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sf2GDJRi5vT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c90846b1"
      },
      "source": [
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "print(f\"Categorical columns: {list(categorical_cols)}\")\n",
        "\n",
        "# Apply One-Hot Encoding\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "encoded_data = encoder.fit_transform(df[categorical_cols])\n",
        "\n",
        "# Create a DataFrame from the encoded data\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "# Drop the original categorical columns and concatenate the encoded DataFrame\n",
        "df_encoded = df.drop(categorical_cols, axis=1)\n",
        "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
        "\n",
        "print(\"\\nDataFrame after One-Hot Encoding:\")\n",
        "display(df_encoded.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns # Import seaborn\n",
        "\n",
        "# Drop the original target column and the 'id' column from the features\n",
        "X = df_encoded.drop(['num', 'id'], axis=1)\n",
        "y = df_encoded['num']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle missing values using the mean strategy for numerical columns\n",
        "# Impute missing values with the mean in training and testing sets\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].isnull().any():\n",
        "        mean_val = X_train[col].mean()\n",
        "        X_train[col] = X_train[col].fillna(mean_val)\n",
        "        if col in X_test.columns:\n",
        "            X_test[col] = X_test[col].fillna(mean_val)\n",
        "\n",
        "# Scale the numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = X_train.select_dtypes(include=np.number).columns # Identify numerical columns *after* one-hot encoding\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix with annotations\n",
        "plt.figure(figsize=(8, 6)) # Add figure for better visualization\n",
        "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='d') # Add annot=True and fmt='d'\n",
        "plt.title('Confusion Matrix') # Add title for clarity\n",
        "plt.xlabel('Predicted Label') # Add xlabel\n",
        "plt.ylabel('True Label') # Add ylabel\n",
        "plt.show() # Show the plot\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "KgB4znYA6PZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(criterion=\"gini\",max_depth=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix with annotations\n",
        "plt.figure(figsize=(8, 6)) # Add figure for better visualization\n",
        "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='d') # Add annot=True and fmt='d'\n",
        "plt.title('Confusion Matrix') # Add title for clarity\n",
        "plt.xlabel('Predicted Label') # Add xlabel\n",
        "plt.ylabel('True Label') # Add ylabel\n",
        "plt.show() # Show the plot\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "cqys_f8x7MG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=10 , criterion=\"gini\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix with annotations\n",
        "plt.figure(figsize=(8, 6)) # Add figure for better visualization\n",
        "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='d') # Add annot=True and fmt='d'\n",
        "plt.title('Confusion Matrix') # Add title for clarity\n",
        "plt.xlabel('Predicted Label') # Add xlabel\n",
        "plt.ylabel('True Label') # Add ylabel\n",
        "plt.show() # Show the plot\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "tIpukbrI7z3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "# Use 'multi:softprob' for multi-class classification with probabilities\n",
        "# Use 'multi:softmax' for multi-class classification with raw predictions\n",
        "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix with annotations\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='d')\n",
        "plt.title('Confusion Matrix - XGBoost')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "IqM_ILI38Kur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dad2a74"
      },
      "source": [
        "# Store results in a DataFrame\n",
        "results = {\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, LogisticRegression(max_iter=1000).fit(X_train, y_train).predict(X_test)),\n",
        "        accuracy_score(y_test, DecisionTreeClassifier(criterion=\"gini\",max_depth=10).fit(X_train, y_train).predict(X_test)),\n",
        "        accuracy_score(y_test, RandomForestClassifier(n_estimators=10 , criterion=\"gini\").fit(X_train, y_train).predict(X_test)),\n",
        "        accuracy_score(y_test, xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss').fit(X_train, y_train).predict(X_test))\n",
        "    ],\n",
        "    'Precision (weighted)': [\n",
        "        precision_score(y_test, LogisticRegression(max_iter=1000).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        precision_score(y_test, DecisionTreeClassifier(criterion=\"gini\",max_depth=10).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        precision_score(y_test, RandomForestClassifier(n_estimators=10 , criterion=\"gini\").fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        precision_score(y_test, xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss').fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0)\n",
        "    ],\n",
        "    'Recall (weighted)': [\n",
        "        recall_score(y_test, LogisticRegression(max_iter=1000).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        recall_score(y_test, DecisionTreeClassifier(criterion=\"gini\",max_depth=10).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        recall_score(y_test, RandomForestClassifier(n_estimators=10 , criterion=\"gini\").fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        recall_score(y_test, xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss').fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0)\n",
        "    ],\n",
        "    'F1-score (weighted)': [\n",
        "        f1_score(y_test, LogisticRegression(max_iter=1000).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        f1_score(y_test, DecisionTreeClassifier(criterion=\"gini\",max_depth=10).fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        f1_score(y_test, RandomForestClassifier(n_estimators=10 , criterion=\"gini\").fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0),\n",
        "        f1_score(y_test, xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss').fit(X_train, y_train).predict(X_test), average='weighted', zero_division=0)\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "display(results_df)\n",
        "\n",
        "# Pick best model based on Accuracy\n",
        "best_model_name = results_df.loc[results_df['Accuracy'].idxmax(), 'Model']\n",
        "print(f\"\\nBest performing model based on Accuracy: {best_model_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e5734ce"
      },
      "source": [
        "import joblib\n",
        "\n",
        "# Train the best model on the full dataset (assuming best model is Logistic Regression based on previous output)\n",
        "# You might need to change this based on the actual best model from the previous step\n",
        "best_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Prepare the full dataset (handle missing values and scale)\n",
        "X_full = df_encoded.drop(['num', 'id'], axis=1)\n",
        "y_full = df_encoded['num']\n",
        "\n",
        "for col in X_full.columns:\n",
        "    if X_full[col].isnull().any():\n",
        "        mean_val = X_full[col].mean()\n",
        "        X_full[col] = X_full[col].fillna(mean_val)\n",
        "\n",
        "scaler_full = StandardScaler()\n",
        "numerical_cols_full = X_full.select_dtypes(include=np.number).columns\n",
        "X_full[numerical_cols_full] = scaler_full.fit_transform(X_full[numerical_cols_full])\n",
        "\n",
        "\n",
        "best_model.fit(X_full, y_full)\n",
        "\n",
        "# Save the model\n",
        "filename = 'best_heart_disease_model.joblib'\n",
        "joblib.dump(best_model, filename)\n",
        "\n",
        "print(f\"\\nBest model ({best_model_name}) trained on full dataset and saved as {filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y45DQdv79S7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}